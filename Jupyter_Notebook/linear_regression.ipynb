{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPj2gUtl-hbR",
        "outputId": "49e83575-30df-4668-f004-3c47f824cb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hypothesis function for linear regression in vectorized form.\n",
            "It uses vectorization to perform matrix-vector multiplication efficiently,\n",
            "allowing to compute model predictions for all examples at once.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"\"\"The hypothesis function for linear regression in vectorized form.\n",
        "It uses vectorization to perform matrix-vector multiplication efficiently,\n",
        "allowing to compute model predictions for all examples at once.\"\"\")\n",
        "\n",
        "def hypothesis(X, theta):\n",
        "    \"\"\"\n",
        "    Hypothesis function for linear regression in vectorized form.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): Feature matrix.\n",
        "        theta (numpy.ndarray): Model parameters vector.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector of model predictions.\n",
        "    \"\"\"\n",
        "    return np.dot(X, theta)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example 1:\\n\")\n",
        "\n",
        "X = np.array([[1, 2], [1, 3], [1, 4]])  # Feature matrix (including the intercept term)\n",
        "theta = np.array([0.5, 0.2])            # Model parameters\n",
        "predictions = hypothesis(X, theta)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7w2pW6B-1D1",
        "outputId": "3deb8356-514e-4a72-827a-8d79362ccc13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "\n",
            "[0.9 1.1 1.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example 2:\\n\")\n",
        "\n",
        "X = np.array([[1, 5], [1, 6], [1, 7]])\n",
        "theta = np.array([0.3, 0.4])\n",
        "predictions = hypothesis(X, theta)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxMOArDb_At6",
        "outputId": "bbb8cb03-65b8-4b2a-9f81-50cf24c91f40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 2:\n",
            "\n",
            "[2.3 2.7 3.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"The function to compute the loss function in vectorized form.\n",
        "This function calculates the mean squared error,\n",
        "which is a common choice for the loss function in linear regression problems.\"\"\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def loss_function(X, y, theta):\n",
        "    \"\"\"\n",
        "    Loss function for linear regression in vectorized form.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): Feature matrix.\n",
        "        y (numpy.ndarray): Target vector.\n",
        "        theta (numpy.ndarray): Model parameters vector.\n",
        "\n",
        "    Returns:\n",
        "        float: Value of the loss function.\n",
        "    \"\"\"\n",
        "    m = len(y)  # Number of training examples\n",
        "    predictions = hypothesis(X, theta) # Compute predictions\n",
        "    squared_errors = (predictions - y) ** 2 # Compute squared errors\n",
        "    cost = (1 / (2 * m)) * np.sum(squared_errors) # Compute mean squared error\n",
        "    return cost\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba_5DTaX_631",
        "outputId": "3a696894-5e66-4ac0-efe7-bdb6f202617e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The function to compute the loss function in vectorized form.\n",
            "This function calculates the mean squared error, \n",
            "which is a common choice for the loss function in linear regression problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example 1:\\n\")\n",
        "\n",
        "X = np.array([[1, 2], [1, 3], [1, 4]])  # Feature matrix (including the intercept term)\n",
        "y = np.array([2, 3, 4])                  # Target vector\n",
        "theta = np.array([0.5, 0.2])            # Model parameters\n",
        "loss = loss_function(X, y, theta)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veJpD3T0ALu-",
        "outputId": "3ff31de6-76bf-40ff-8a1c-7bf1046e2bc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "\n",
            "2.0183333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example 2:\\n\")\n",
        "\n",
        "X = np.array([[1, 5], [1, 6], [1, 7]])\n",
        "y = np.array([3, 4, 5])\n",
        "theta = np.array([0.3, 0.4])\n",
        "loss = loss_function(X, y, theta)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBt3YsQnATKu",
        "outputId": "28671a30-bdd5-4674-b458-8b5336525cf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 2:\n",
            "\n",
            "0.9649999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The computing the gradient of the loss function with respect to the model parameters.\")\n",
        "\n",
        "def gradient_descent_step(X, y, theta, learning_rate):\n",
        "    \"\"\"\n",
        "    Perform one step of gradient descent.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): Feature matrix.\n",
        "        y (numpy.ndarray): Target vector.\n",
        "        theta (numpy.ndarray): Model parameters vector.\n",
        "        learning_rate (float): Learning rate for gradient descent.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Updated model parameters vector.\n",
        "    \"\"\"\n",
        "    m = len(y)  # Number of training examples\n",
        "    predictions = hypothesis(X, theta) # Compute predictions\n",
        "    errors = predictions - y # Compute errors\n",
        "    gradient = (1 / m) * np.dot(X.T, errors) # Compute gradient\n",
        "    new_theta = theta - learning_rate * gradient  # Update parameters\n",
        "    return new_theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6KXcxFeBehD",
        "outputId": "090c07ad-6888-409b-9316-517e3e0caf06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The computing the gradient of the loss function with respect to the model parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking how this function works on an example:\\n\")\n",
        "\n",
        "# Define feature matrix X, target vector y, initial parameters theta, and learning rate\n",
        "X = np.array([[1, 2], [1, 3], [1, 4]])  # Feature matrix (including the intercept term)\n",
        "y = np.array([2, 3, 4])                  # Target vector\n",
        "theta = np.array([0.5, 0.2])             # Initial model parameters\n",
        "learning_rate = 0.1                      # Learning rate for gradient descent\n",
        "\n",
        "# Perform one step of gradient descent\n",
        "theta = gradient_descent_step(X, y, theta, learning_rate)\n",
        "print(\"Updated parameters:\", theta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkvpgkBBuwJ",
        "outputId": "c074b85a-d332-499a-be24-f1899adc5487"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking how this function works on an example:\n",
            "\n",
            "Updated parameters: [0.69       0.82333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The computing the gradient of the loss function with respect to the model parameters.\")\n",
        "\n",
        "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
        "    costs = []\n",
        "    for i in range(iterations):\n",
        "        theta = gradient_descent_step(X, y, theta, learning_rate)\n",
        "        cost = loss_function(X, y, theta)\n",
        "        costs.append(cost)\n",
        "        # print(f\"Iteration {i+1}/{iterations}, Cost: {cost}\")\n",
        "    return theta, costs"
      ],
      "metadata": {
        "id": "croTsInG7vT7",
        "outputId": "1992399d-4070-43fc-a920-18249922f48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The computing the gradient of the loss function with respect to the model parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import requests\n",
        "\n",
        "# URL of the CSV file\n",
        "url = \"https://raw.githubusercontent.com/Anastasia-front/data-science/main/csv/Housing.csv\"\n",
        "\n",
        "# Read the CSV file content from the URL\n",
        "response = requests.get(url)\n",
        "content = response.content.decode(\"utf-8\")\n",
        "\n",
        "# Use pandas read_csv to load the CSV data into a DataFrame\n",
        "df = pd.read_csv(StringIO(content))\n",
        "\n",
        "# Insert a column of ones at the beginning for the intercept term\n",
        "df.insert(0, 'x0', 1)\n",
        "\n",
        "# Splitting the data into features and target value\n",
        "X = df[['x0', 'area', 'bedrooms', 'bathrooms']].values\n",
        "y = df['price'].values\n",
        "\n",
        "# Initial values of parameters\n",
        "theta = np.zeros(X.shape[1])\n",
        "\n",
        "# Learning rate and number of iterations\n",
        "learning_rate = 0.00000001\n",
        "iterations = 10000\n",
        "\n",
        "# Running gradient descent\n",
        "final_theta, costs = gradient_descent(X, y, theta, learning_rate, iterations)\n",
        "\n",
        "print(\"Optimal parameters w:\", final_theta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEHwoUrZEm8G",
        "outputId": "4fdc9df4-328d-47b9-b8cf-8a46e370c24e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal parameters w: [ 36.07342826 855.61928545 136.69255633  76.90357991]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of parameters using an analytical solution\n",
        "w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "\n",
        "print(\"Optimal parameters w:\", w)"
      ],
      "metadata": {
        "id": "aGcvlvMMBSIF",
        "outputId": "9d85d6f5-319d-49b2-e955-3f616772a538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal parameters w: [-1.73171608e+05  3.78762754e+02  4.06820034e+05  1.38604950e+06]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Separation of data into features and target value\n",
        "X = df[['area', 'bathrooms', 'bedrooms']].values\n",
        "y = df['price'].values\n",
        "\n",
        "# Learning a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Getting predicted values\n",
        "predictions_sklearn = model.predict(X)\n",
        "\n",
        "print(\"Predicted values using LinearRegression with scikit-learn:\")\n",
        "print(predictions_sklearn[:5])"
      ],
      "metadata": {
        "id": "RGknuDdkBXhY",
        "outputId": "c8808be1-f4aa-48b9-9661-0b15fdc1658c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values using LinearRegression with scikit-learn:\n",
            "[ 7036627.15462756 10392020.79073061  7591864.51496454  7066928.17491437\n",
            "  5650577.65683656]\n"
          ]
        }
      ]
    }
  ]
}